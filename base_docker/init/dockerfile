# docker build -t keti/llama_cpp-cuda12.1 .

FROM pytorch/pytorch:2.3.1-cuda12.1-cudnn8-devel
# FROM ghcr.io/abetlen/llama-cpp-python:v0.2.83
LABEL maintainer="KETI AIRC sankim <kimsan0622@keti.re.kr>"

RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    software-properties-common \
    cmake \
    git \
    ccache

RUN CMAKE_ARGS="-DGGML_CUDA=on -DLLAVA_BUILD=off" pip install --verbose llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
